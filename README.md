# ğŸ¤ Voice-Enabled AI Assistant  
**AI Intern (LLMs & Voice AI) â€“ Technical Assessment**

---

## Overview
This project implements a **voice-enabled AI assistant** that accepts spoken input, converts it to text, generates a response using a Large Language Model (LLM), converts the response back to speech, and returns the audio output.

The focus of this project is on **clean architecture, modular design, and reasoning**, rather than UI complexity.

Both **real APIs (OpenAI)** and production-style design patterns are used, while keeping the system minimal and easy to understand.

---

## Problem Statement (Assessment Context)

The assistant should:
1. Accept user voice input  
2. Convert **Speech â†’ Text (STT)**  
3. Generate a response using an **LLM**  
4. Convert **Text â†’ Speech (TTS)**  
5. Return the audio response  

A UI is **not required** for evaluation (a small demo UI is included only for testing).

---

## Part A â€“ System Design

### Components

User Audio
â†“
Speech-to-Text (Whisper)
â†“
Conversation Manager (Session History)
â†“
LLM (Reasoning)
â†“
Text-to-Speech
â†“
Audio Response



### Core Services

| Component | Responsibility |
|--------|----------------|
| STTService | Converts audio bytes to text |
| LLMService | Generates responses using an LLM |
| TTSService | Converts text to speech |
| VoiceAssistant | Orchestrates pipeline & sessions |
| FastAPI API | Exposes HTTP endpoints |

---

### Data Flow

1. Client sends recorded audio to `/voice`
2. Audio bytes â†’ STT â†’ transcript
3. Transcript added to session history
4. History passed to LLM
5. LLM generates response text
6. Response text â†’ TTS â†’ audio bytes
7. Audio returned as Base64

---

### Latency, Cost & Failure Considerations

| Area | Consideration |
|----|-------------|
| STT | Network + inference latency |
| LLM | Token cost & response length |
| TTS | Audio generation delay |
| Sessions | In-memory, non-persistent |
| Failures | Handled gracefully with fallbacks |

Design decisions:
- Responses limited to **2 sentences** for voice UX
- Conversation history capped to last **10 messages**
- No streaming to keep implementation simple
- Stateless backend except for in-memory sessions

---

## Part B â€“ Implementation

### High-Level Pipeline

```python
def voice_assistant(audio_input):
    text = speech_to_text(audio_input)
    reply = generate_llm_response(text)
    audio = text_to_speech(reply)
    return audio
## ğŸ“‚ Project Structure
```
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py                 # FastAPI Endpoints
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â””â”€â”€ assistant.py              # Orchestration (STT -> LLM -> TTS)
â”‚   â”‚
â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â””â”€â”€ openai_stt.py             # Whisper Wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ openai_llm.py             # GPT Wrapper (History-aware)
â”‚   â”‚
â”‚   â”œâ”€â”€ tts/
â”‚   â”‚   â””â”€â”€ openai_tts.py             # TTS Wrapper
â”‚   â”‚
â”‚   â””â”€â”€ config.py                     # Model & API configurations
â”‚
â”œâ”€â”€ main.py                           # Entry Point
â””â”€â”€ requirements.txt                  # Pinned dependencies
```


## ğŸ§  System Architecture

### ğŸ”„ Voice Assistant Pipeline
This application follows a modular **Speech â†’ Intelligence â†’ Speech** pipeline:

1. **Speech-to-Text (STT)** â€“ Converts user voice into text  
2. **Large Language Model (LLM)** â€“ Generates intelligent responses  
3. **Text-to-Speech (TTS)** â€“ Converts assistant responses back into audio  

---

## âš™ï¸ Core Components

### ğŸ›ï¸ Voice Assistant Orchestrator
- Coordinates the full pipeline **STT â†’ LLM â†’ TTS**
- Maintains **session-based conversation history**
- Automatically trims history to control token usage and latency
- Ensures smooth conversational flow

---

### ğŸ™ï¸ STT Service
- Powered by **OpenAI Whisper (`whisper-1`)**
- Converts raw audio bytes into text transcripts
- Optimized for multi-accent speech recognition

---

### ğŸ¤– LLM Service
- Uses **GPT-based chat completion**
- Implements a **system prompt** to:
  - Keep responses concise
  - Maintain voice-friendly conversational tone
- Supports context-aware conversation using session memory

---

### ğŸ”Š TTS Service
- Converts assistant responses into natural speech audio
- Returns raw audio bytes for playback
- Uses configurable voice and model selection

---

## ğŸŒ API Endpoints

### ğŸ¤ `POST /api/voice`
Processes user audio and returns:

```json
{
  "transcript": "User speech text",
  "reply": "Assistant response",
  "audio": "Base64-encoded audio"
}
```

---

### ğŸ§¾ `POST /api/start_session`
- Initializes a new conversation session  
- Enables contextual multi-turn conversation  

---

### ğŸ›‘ `POST /api/end_session`
- Terminates an active session  
- Clears stored conversation history  

---

## ğŸ”§ Configuration

### ğŸŒ± Environment Variables
```
OPENAI_API_KEY=your_api_key_here
```

---

### ğŸ§© Model Configuration
```python
LLM_MODEL = "gpt-4o-mini"
STT_MODEL = "whisper-1"
TTS_MODEL = "gpt-4o-mini-tts"
TTS_VOICE = "alloy"
```

---

## ğŸ–¥ï¸ Frontend (Demo Only)

A lightweight demonstration frontend is included to:

- ğŸ¤ Record microphone input
- ğŸ¤« Detect silence using VAD-style logic
- ğŸ“¡ Send audio to backend
- ğŸ”Š Play assistant voice responses
- âœ‹ Support barge-in (interrupt assistant playback)

> The frontend is provided only for demonstration and is not required for assessment.

---

## âš–ï¸ Design Trade-offs

| Decision | Reason |
|----------|-----------|
| In-memory session storage | Reduces complexity and setup time |
| Synchronous processing | Improves readability and debugging |
| No streaming implementation | Keeps architecture simpler |
| Short response generation | Optimized for voice interaction latency |

---

## ğŸ“Š Evaluation Alignment

This project highlights:

- âœ… Strong system architecture design  
- âœ… Practical implementation of LLM workflows  
- âœ… Understanding of Voice AI constraints  
- âœ… Clean and modular code structure  
- âœ… Explicit documentation of trade-offs  

---

## ğŸ“ Notes
- Some implementations are intentionally simplified  
- Architecture is designed for easy extension:
  - Streaming responses  
  - Database session persistence  
  - Horizontal scaling  

---

## ğŸ‘¨â€ğŸ’» Author
**Swastik**  
AI Intern Candidate â€” LLMs & Voice AI
